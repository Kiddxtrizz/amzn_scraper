{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\n",
      " Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\n",
      " Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\n",
      " Mozilla/5.0 (X11; Linux i686; rv:109.0) Gecko/20100101 Firefox/121.0\n",
      " Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/121.0\n",
      " Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0\n",
      " Mozilla/5.0 (Windows NT 10.0; WOW64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0\n",
      " Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0\n",
      " Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0\n",
      " Mozilla/5.0 (Windows NT 10.0; Win64; x64; Xbox; Xbox One) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edge/44.18363.8131\n",
      " Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edg/123.0.2420.81\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of User Agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux i686; rv:109.0) Gecko/20100101 Firefox/121.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/121.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:115.0) Gecko/20100101 Firefox/115.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; Xbox; Xbox One) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edge/44.18363.8131',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 Edg/123.0.2420.81'\n",
    "]\n",
    "\n",
    "# Index to track the current User Agent\n",
    "user_agent_index = 0\n",
    "\n",
    "# Make a request with a rotated User Agent\n",
    "def make_request(url):\n",
    "    global user_agent_index\n",
    "    headers = {'User-Agent': user_agents[user_agent_index]}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    user_agent_index = (user_agent_index + 1) % len(user_agents)\n",
    "    return response.text\n",
    "\n",
    "# Scrape product title from Amazon product page\n",
    "url = 'https://www.amazon.com/Basic-Care-Ibuprofen-Tablets-Count/dp/B074F297T8/ref=zg_bs_g_10079990011_d_sccl_1/135-2176971-2462156?psc=1'\n",
    "\n",
    "for _ in range(len(user_agents)):\n",
    "    html_content = make_request(url)\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    title_tag = soup.find('span', {'id': 'productTitle'})\n",
    "    title = title_tag.get_text(strip=True) if title_tag else ''\n",
    "\n",
    "    print(title, user_agents[_])\n",
    "    time.sleep(20) # Add a delay of 2 seconds between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title: Amazon Basic Care Ibuprofen Tablets 200 mg, Pain Reliever/Fever Reducer, Body Aches, Headache, Arthritis Pain Relief and More, 500 Count\n",
      "Product Price: \n",
      "Product Rating: 77,335 ratings\n",
      "Number of Reviews: 4.84.8 out of 5 stars\n",
      "Product Title: Amazon Basic Care Ibuprofen Tablets 200 mg, Pain Reliever/Fever Reducer, Body Aches, Headache, Arthritis Pain Relief and More, 500 Count\n",
      "Product Price: \n",
      "Product Rating: 77,335\n",
      "Number of Reviews: 4.8 out of 5 stars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct Rating: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Reviews: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreviews\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Add a delay of 2 seconds between requests\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of User Agents\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux i686; rv:109.0) Gecko/20100101 Firefox/121.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/121.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0'\n",
    "]\n",
    "\n",
    "# Index to track the current User Agent\n",
    "user_agent_index = 0\n",
    "\n",
    "# Make a request with a rotated User Agent\n",
    "def make_request(url):\n",
    "    global user_agent_index\n",
    "    headers = {'User-Agent': user_agents[user_agent_index],\n",
    "                'Accept-Language': 'da, en-gb, en',\n",
    "                'Accept-Encoding': 'gzip, deflate, br',\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "                'Referer': 'https://www.google.com/'\n",
    "                }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    user_agent_index = (user_agent_index + 1) % len(user_agents)\n",
    "    return response.text\n",
    "\n",
    "# Scrape product title from Amazon product page\n",
    "url = 'https://www.amazon.com/Basic-Care-Ibuprofen-Tablets-Count/dp/B074F297T8/ref=zg_bs_g_10079990011_d_sccl_1/135-2176971-2462156?psc=1'\n",
    "\n",
    "for _ in range(len(user_agents)):\n",
    "    html_content = make_request(url)\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Extract product title\n",
    "    title_tag = soup.find('span', {'id': 'productTitle'})\n",
    "    title = title_tag.get_text(strip=True) if title_tag else ''\n",
    "\n",
    "    # Extract product price\n",
    "    price_tag = soup.find('span', {'id': 'priceblock_ourprice'})\n",
    "    price = price_tag.get_text(strip=True) if price_tag else ''\n",
    "\n",
    "\n",
    "    # Extract product rating\n",
    "    rating_tag = soup.find('span', {'id': 'acrCustomerReviewText'})\n",
    "    rating = rating_tag.get_text(strip=True) if rating_tag else ''\n",
    "\n",
    "    # Extract number of reviews\n",
    "    reviews_tag = soup.find('span', {'id': 'acrPopover'})\n",
    "    reviews = reviews_tag.get_text(strip=True) if reviews_tag else ''\n",
    "\n",
    "    # Print the extracted information\n",
    "    print(f'Product Title: {title}')\n",
    "    print(f'Product Price: {price}')\n",
    "    print(f'Product Rating: {rating}')\n",
    "    print(f'Number of Reviews: {reviews}')\n",
    "    \n",
    "    time.sleep(40) # Add a delay of 2 seconds between requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://www.amazon.com/Bose-QuietComfort-45-Bluetooth-Canceling-Headphones/dp/B098FKXT8L'\n",
    "\n",
    "custom_headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/121.0',\n",
    "    'Accept-Language': 'da, en-gb, en',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Referer': 'https://www.google.com/'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers= custom_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "visited_urls = set()\n",
    "\n",
    "def get_product_info(url):\n",
    "    response = requests.get(url, headers=custom_headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error in getting webpage: {url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "\n",
    "    title_element = soup.select_one(\"#productTitle\")\n",
    "    title = title_element.text.strip() if title_element else None\n",
    "\n",
    "    price_element = soup.select_one('span.a-offscreen')\n",
    "    price = price_element.text if price_element else None\n",
    "\n",
    "    rating_element = soup.select_one(\"#acrPopover\")\n",
    "    rating_text = rating_element.attrs.get(\"title\") if rating_element else None\n",
    "    rating = rating_text.replace(\"out of 5 stars\", \"\") if rating_text else None\n",
    "\n",
    "    image_element = soup.select_one(\"#landingImage\")\n",
    "    image = image_element.attrs.get(\"src\") if image_element else None\n",
    "\n",
    "    description_element = soup.select_one(\"#productDescription\")\n",
    "    description = description_element.text.strip() if description_element else None\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"price\": price,\n",
    "        \"rating\": rating,\n",
    "        \"image\": image,\n",
    "        \"description\": description,\n",
    "        \"url\": url\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_listing(listing_url):\n",
    "    global visited_urls\n",
    "    response = requests.get(listing_url, headers=custom_headers)\n",
    "    print(response.status_code)\n",
    "    soup_search = BeautifulSoup(response.text, \"lxml\")\n",
    "    link_elements = soup_search.select(\"[data-asin] h2 a\")\n",
    "    page_data = []\n",
    "\n",
    "    for link in link_elements:\n",
    "        full_url = urljoin(listing_url, link.attrs.get(\"href\"))\n",
    "        if full_url not in visited_urls:\n",
    "            visited_urls.add(full_url)\n",
    "            print(f\"Scraping product from {full_url[:100]}\", flush=True)\n",
    "            product_info = get_product_info(full_url)\n",
    "            if product_info:\n",
    "                page_data.append(product_info)\n",
    "\n",
    "    next_page_el = soup_search.select_one('a.s-pagination-next')\n",
    "    if next_page_el:\n",
    "        next_page_url = next_page_el.attrs.get('href')\n",
    "        next_page_url = urljoin(listing_url, next_page_url)\n",
    "        print(f'Scraping next page: {next_page_url}', flush=True)\n",
    "        page_data += parse_listing(next_page_url)\n",
    "\n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amzn-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
